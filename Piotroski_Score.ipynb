{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "tickers = [\"AXP\",\"AAPL\",\"BA\",\"CAT\",\"CVX\",\"CSCO\",\"DIS\",\"DOW\", \"XOM\",\n",
    "           \"HD\",\"IBM\",\"INTC\",\"JNJ\",\"KO\",\"MCD\",\"MMM\",\"MRK\",\"MSFT\",\n",
    "           \"NKE\",\"PFE\",\"PG\",\"TRV\",\"UTX\",\"UNH\",\"VZ\",\"V\",\"WMT\",\"WBA\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#list of tickers whose financial data needs to be extracted\n",
    "financial_dir_cy = {} #directory to store current year's information\n",
    "financial_dir_py = {} #directory to store last year's information\n",
    "financial_dir_py2 = {} #directory to store last to last year's information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "scraping financial statement data for  AXP\n",
      "scraping financial statement data for  AAPL\n",
      "scraping financial statement data for  BA\n",
      "scraping financial statement data for  CAT\n",
      "scraping financial statement data for  CVX\n",
      "scraping financial statement data for  CSCO\n",
      "scraping financial statement data for  DIS\n",
      "scraping financial statement data for  DOW\n",
      "scraping financial statement data for  XOM\n",
      "scraping financial statement data for  HD\n",
      "scraping financial statement data for  IBM\n",
      "scraping financial statement data for  INTC\n",
      "scraping financial statement data for  JNJ\n",
      "scraping financial statement data for  KO\n",
      "scraping financial statement data for  MCD\n",
      "scraping financial statement data for  MMM\n",
      "scraping financial statement data for  MRK\n",
      "scraping financial statement data for  MSFT\n",
      "scraping financial statement data for  NKE\n",
      "scraping financial statement data for  PFE\n",
      "scraping financial statement data for  PG\n",
      "scraping financial statement data for  TRV\n",
      "scraping financial statement data for  UTX\n",
      "scraping financial statement data for  UNH\n",
      "scraping financial statement data for  VZ\n",
      "scraping financial statement data for  V\n",
      "scraping financial statement data for  WMT\n",
      "scraping financial statement data for  WBA\n"
     ]
    }
   ],
   "source": [
    "for ticker in tickers:\n",
    "    try:\n",
    "        print(\"scraping financial statement data for \",ticker)\n",
    "        temp_dir = {}\n",
    "        temp_dir2 = {}\n",
    "        temp_dir3 = {}\n",
    "    #getting balance sheet data from yahoo finance for the given ticker\n",
    "        url = 'https://in.finance.yahoo.com/quote/'+ticker+'/balance-sheet?p='+ticker\n",
    "        page = requests.get(url)\n",
    "        page_content = page.content\n",
    "        soup = BeautifulSoup(page_content,'html.parser')\n",
    "        tabl = soup.find_all(\"div\", {\"class\" : \"M(0) Whs(n) BdEnd Bdc($seperatorColor) D(itb)\"})\n",
    "        for t in tabl:\n",
    "            rows = t.find_all(\"div\", {\"class\" : \"rw-expnded\"})\n",
    "            for row in rows:\n",
    "                temp_dir[row.get_text(separator='|').split(\"|\")[0]]=row.get_text(separator='|').split(\"|\")[1]\n",
    "                temp_dir2[row.get_text(separator='|').split(\"|\")[0]]=row.get_text(separator='|').split(\"|\")[2]\n",
    "                temp_dir3[row.get_text(separator='|').split(\"|\")[0]]=row.get_text(separator='|').split(\"|\")[3]\n",
    "        \n",
    "        #getting income statement data from yahoo finance for the given ticker\n",
    "        url = 'https://in.finance.yahoo.com/quote/'+ticker+'/financials?p='+ticker\n",
    "        page = requests.get(url)\n",
    "        page_content = page.content\n",
    "        soup = BeautifulSoup(page_content,'html.parser')\n",
    "        tabl = soup.find_all(\"div\", {\"class\" : \"M(0) Whs(n) BdEnd Bdc($seperatorColor) D(itb)\"})\n",
    "        for t in tabl:\n",
    "            rows = t.find_all(\"div\", {\"class\" : \"rw-expnded\"})\n",
    "            for row in rows:\n",
    "                temp_dir[row.get_text(separator='|').split(\"|\")[0]]=row.get_text(separator='|').split(\"|\")[1]\n",
    "                temp_dir2[row.get_text(separator='|').split(\"|\")[0]]=row.get_text(separator='|').split(\"|\")[2]\n",
    "                temp_dir3[row.get_text(separator='|').split(\"|\")[0]]=row.get_text(separator='|').split(\"|\")[3]\n",
    "        \n",
    "        #getting cashflow statement data from yahoo finance for the given ticker\n",
    "        url = 'https://in.finance.yahoo.com/quote/'+ticker+'/cash-flow?p='+ticker\n",
    "        page = requests.get(url)\n",
    "        page_content = page.content\n",
    "        soup = BeautifulSoup(page_content,'html.parser')\n",
    "        tabl = soup.find_all(\"div\", {\"class\" : \"M(0) Whs(n) BdEnd Bdc($seperatorColor) D(itb)\"})\n",
    "        for t in tabl:\n",
    "            rows = t.find_all(\"div\", {\"class\" : \"rw-expnded\"})\n",
    "            for row in rows:\n",
    "                temp_dir[row.get_text(separator='|').split(\"|\")[0]]=row.get_text(separator='|').split(\"|\")[1]\n",
    "                temp_dir2[row.get_text(separator='|').split(\"|\")[0]]=row.get_text(separator='|').split(\"|\")[2]\n",
    "                temp_dir3[row.get_text(separator='|').split(\"|\")[0]]=row.get_text(separator='|').split(\"|\")[3] \n",
    "        \n",
    "        #combining all extracted information with the corresponding ticker\n",
    "        financial_dir_cy[ticker] = temp_dir\n",
    "        financial_dir_py[ticker] = temp_dir2\n",
    "        financial_dir_py2[ticker] = temp_dir3\n",
    "    except:\n",
    "        print(\"Problem scraping data for \",ticker)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#storing information in pandas dataframe\n",
    "combined_financials_cy = pd.DataFrame(financial_dir_cy)\n",
    "#combined_financials_cy.dropna(axis=1,inplace=True) #dropping columns with NaN values\n",
    "combined_financials_py = pd.DataFrame(financial_dir_py)\n",
    "#combined_financials_py.dropna(axis=1,inplace=True)\n",
    "combined_financials_py2 = pd.DataFrame(financial_dir_py2)\n",
    "#combined_financials_py2.dropna(axis=1,inplace=True)\n",
    "tickers = combined_financials_cy.columns #updating the tickers list based on only those tickers whose values were successfully extracted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
